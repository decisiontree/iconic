{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import pickle\n",
    "from config import ColumnConfigs,AllModelImputer,ToLowerCase,ConvertDType,VarRemover\n",
    "import util\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/phan5/bigjoin_bigquery/icon\n"
     ]
    }
   ],
   "source": [
    "work_dir = os.getcwd()\n",
    "sys.path.append(work_dir)\n",
    "os.chdir(work_dir)\n",
    "print(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_json(\"data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Defining class label - gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inferred gender by all gender related buy ; find customers with only male related purchase\n",
    "data_raw.loc[(data_raw.male_items+data_raw.mapp_items+data_raw.mftw_items+data_raw.macc_items+data_raw.mspt_items>0) \n",
    "        & (data_raw.female_items+data_raw.wapp_items+data_raw.wftw_items+data_raw.wacc_items+data_raw.wspt_items==0),\n",
    "            'gender'] = 1\n",
    "#inferred gender by all gender related buy ; find customers with only female related purchase\n",
    "data_raw.loc[(data_raw.male_items+data_raw.mapp_items+data_raw.mftw_items+data_raw.macc_items+data_raw.mspt_items==0) \n",
    "        & (data_raw.female_items+data_raw.wapp_items+data_raw.wftw_items+data_raw.wacc_items+data_raw.wspt_items>0),\n",
    "            'gender'] = 0\n",
    "\n",
    "#As both male and female columns have been used as target geneation, they are expected very correlated with label;\n",
    "#remove them from later analysis\n",
    "target_related_feature=['male_items','mapp_items','mftw_items','macc_items','mspt_items'\\\n",
    "                       ,'female_items','wapp_items','wftw_items','wacc_items','wspt_items']\n",
    "data_raw.drop(target_related_feature, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30133, 34)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#1.pick up training records only \n",
    "data_all=data_raw[data_raw.gender.isin([0,1])].copy(deep=True)\n",
    "print(data_all.shape)\n",
    "\n",
    "#2.fix the buy date issue (days_since_last_order, divide by 24)\n",
    "data_all['days_since_last_order'] = data_all['days_since_last_order']/24\n",
    "\n",
    "#3.make sure customer id is unique (drop duplicate records in this case)\n",
    "data_all.drop_duplicates(inplace=True)\n",
    "\n",
    "#print(data_all.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Preprocess features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_all = data_all['gender'].copy(deep=True)\n",
    "y_train_all = pd.to_numeric(y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Variable Dropped]\n",
      "[Convert Found] - 0 columns to numeric. 2 columns to category.\n",
      "[DType Convert Done] - 2 columns to category.\n",
      "[Detecting Imputation]:\n",
      "000000000000000.00000000000000..  |33 (100.00 %)\n",
      "[Imputation Start]:\n",
      "      =                           |33 (100.00 %)\n",
      "[Lower Case Conversion Done]:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phan5/bigjoin_bigquery/icon/config.py:68: UserWarning: [Missing Config - gender]\n",
      "  warnings.warn(\"[Missing Config - \" + column + \"]\"  )\n"
     ]
    }
   ],
   "source": [
    "config_file = pd.read_csv(os.path.join(work_dir, 'datatype.csv'), dtype=object)\n",
    "newConfig = ColumnConfigs(config_file)\n",
    "\n",
    "modelTest = Pipeline([\n",
    "    ('remover', VarRemover(newConfig)),\n",
    "    ('conveter', ConvertDType(newConfig)),\n",
    "    ('imputer', AllModelImputer(newConfig)), #this line is causing error\n",
    "    ('lower', ToLowerCase()),\n",
    "])\n",
    "\n",
    "features_all = modelTest.fit_transform(data_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName = 'feat_proc_obj'\n",
    "fileObject = open(fileName, 'wb')\n",
    "pickle.dump(modelTest, fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName = 'features'\n",
    "fileObject = open(fileName, 'wb')\n",
    "pickle.dump(modelTest, fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29958, 33)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29958, 34)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29958, 33)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_all = .drop(,axis = 1)\n",
    "X_train_all = features_all._get_numeric_data()\n",
    "num_cols = X_train_all.columns.tolist()\n",
    "cat_cols = [col for col in features_all.columns if col not in  num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afterpay_payments</th>\n",
       "      <th>android_orders</th>\n",
       "      <th>apple_payments</th>\n",
       "      <th>average_discount_onoffer</th>\n",
       "      <th>average_discount_used</th>\n",
       "      <th>cancels</th>\n",
       "      <th>coupon_discount_applied</th>\n",
       "      <th>curvy_items</th>\n",
       "      <th>days_since_first_order</th>\n",
       "      <th>days_since_last_order</th>\n",
       "      <th>...</th>\n",
       "      <th>parcelpoint_orders</th>\n",
       "      <th>redpen_discount_used</th>\n",
       "      <th>returns</th>\n",
       "      <th>revenue</th>\n",
       "      <th>sacc_items</th>\n",
       "      <th>shipping_addresses</th>\n",
       "      <th>unisex_items</th>\n",
       "      <th>vouchers</th>\n",
       "      <th>work_orders</th>\n",
       "      <th>coupon_discount_applied___mflg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2053</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6983</td>\n",
       "      <td>6983.3887</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>94.59</td>\n",
       "      <td>0</td>\n",
       "      <td>40.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2034</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>45.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>5019.3247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2077</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>118.18</td>\n",
       "      <td>0</td>\n",
       "      <td>117.27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    afterpay_payments  android_orders  apple_payments  \\\n",
       "4                   0               0               0   \n",
       "6                   0               0               0   \n",
       "9                   0               0               0   \n",
       "13                  0               0               0   \n",
       "17                  0               0               0   \n",
       "\n",
       "    average_discount_onoffer  average_discount_used  cancels  \\\n",
       "4                     0.0000                 0.0000        0   \n",
       "6                     0.6983              6983.3887        0   \n",
       "9                     0.0000                 0.0000        1   \n",
       "13                    0.0000                 0.0000        0   \n",
       "17                    0.5019              5019.3247        0   \n",
       "\n",
       "    coupon_discount_applied  curvy_items  days_since_first_order  \\\n",
       "4                       0.0            0                    2053   \n",
       "6                       0.0            0                    2042   \n",
       "9                       0.0            0                    2034   \n",
       "13                      0.0            0                    2025   \n",
       "17                      0.0            0                    2077   \n",
       "\n",
       "    days_since_last_order               ...                parcelpoint_orders  \\\n",
       "4                  2053.0               ...                                 0   \n",
       "6                  2042.0               ...                                 0   \n",
       "9                  2034.0               ...                                 0   \n",
       "13                 2025.0               ...                                 0   \n",
       "17                 2077.0               ...                                 0   \n",
       "\n",
       "    redpen_discount_used  returns  revenue  sacc_items  shipping_addresses  \\\n",
       "4                   0.00        0     0.00           0                   1   \n",
       "6                  94.59        0    40.86           0                   1   \n",
       "9                   0.00        0     0.00           0                   1   \n",
       "13                  0.00        1    45.41           0                   1   \n",
       "17                118.18        0   117.27           0                   1   \n",
       "\n",
       "    unisex_items  vouchers  work_orders  coupon_discount_applied___mflg  \n",
       "4              0         0            0                               0  \n",
       "6              0         0            0                               0  \n",
       "9              0         0            0                               0  \n",
       "13             0         0            0                               0  \n",
       "17             0         0            0                               0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Preprocess features, Removing dense categories add onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 20\n",
    "to_remove = []\n",
    "for col in cat_cols:\n",
    "    levels = len(features_all[col].value_counts())\n",
    "    if levels > threshold:\n",
    "        to_remove.append(col)\n",
    "\n",
    "features_all.drop(to_remove, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_all = features_all._get_numeric_data()\n",
    "num_cols = X_train_all.columns.tolist()\n",
    "cat_cols = [col for col in features_all.columns if col not in  num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29958, 30)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(cat_cols) > 0:\n",
    "    for feature in cat_cols:\n",
    "        one_hot = pd.get_dummies(features_all[feature],prefix=feature+'||')\n",
    "        X_train_all = X_train_all.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afterpay_payments</th>\n",
       "      <th>android_orders</th>\n",
       "      <th>apple_payments</th>\n",
       "      <th>average_discount_onoffer</th>\n",
       "      <th>average_discount_used</th>\n",
       "      <th>cancels</th>\n",
       "      <th>coupon_discount_applied</th>\n",
       "      <th>curvy_items</th>\n",
       "      <th>days_since_first_order</th>\n",
       "      <th>days_since_last_order</th>\n",
       "      <th>...</th>\n",
       "      <th>unisex_items</th>\n",
       "      <th>vouchers</th>\n",
       "      <th>work_orders</th>\n",
       "      <th>coupon_discount_applied___mflg</th>\n",
       "      <th>is_newsletter_subscriber||_n</th>\n",
       "      <th>is_newsletter_subscriber||_y</th>\n",
       "      <th>paypal_payments||_0</th>\n",
       "      <th>paypal_payments||_1</th>\n",
       "      <th>cc_payments||_0</th>\n",
       "      <th>cc_payments||_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2053</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6983</td>\n",
       "      <td>6983.3887</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2034</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>5019.3247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2077</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    afterpay_payments  android_orders  apple_payments  \\\n",
       "4                   0               0               0   \n",
       "6                   0               0               0   \n",
       "9                   0               0               0   \n",
       "13                  0               0               0   \n",
       "17                  0               0               0   \n",
       "\n",
       "    average_discount_onoffer  average_discount_used  cancels  \\\n",
       "4                     0.0000                 0.0000        0   \n",
       "6                     0.6983              6983.3887        0   \n",
       "9                     0.0000                 0.0000        1   \n",
       "13                    0.0000                 0.0000        0   \n",
       "17                    0.5019              5019.3247        0   \n",
       "\n",
       "    coupon_discount_applied  curvy_items  days_since_first_order  \\\n",
       "4                       0.0            0                    2053   \n",
       "6                       0.0            0                    2042   \n",
       "9                       0.0            0                    2034   \n",
       "13                      0.0            0                    2025   \n",
       "17                      0.0            0                    2077   \n",
       "\n",
       "    days_since_last_order       ...         unisex_items  vouchers  \\\n",
       "4                  2053.0       ...                    0         0   \n",
       "6                  2042.0       ...                    0         0   \n",
       "9                  2034.0       ...                    0         0   \n",
       "13                 2025.0       ...                    0         0   \n",
       "17                 2077.0       ...                    0         0   \n",
       "\n",
       "    work_orders  coupon_discount_applied___mflg  is_newsletter_subscriber||_n  \\\n",
       "4             0                               0                             0   \n",
       "6             0                               0                             1   \n",
       "9             0                               0                             0   \n",
       "13            0                               0                             0   \n",
       "17            0                               0                             1   \n",
       "\n",
       "    is_newsletter_subscriber||_y  paypal_payments||_0  paypal_payments||_1  \\\n",
       "4                              1                    1                    0   \n",
       "6                              0                    1                    0   \n",
       "9                              1                    1                    0   \n",
       "13                             1                    1                    0   \n",
       "17                             0                    1                    0   \n",
       "\n",
       "    cc_payments||_0  cc_payments||_1  \n",
       "4                 0                1  \n",
       "6                 0                1  \n",
       "9                 0                1  \n",
       "13                0                1  \n",
       "17                0                1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29958, 36)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage3 Fit XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split Group B data into validation and test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=20180814)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phan5/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "xgbtrain_all = xgb.DMatrix(data = X_train_all, label = y_train_all\n",
    "#                            , weight = X_weights_all\n",
    "                           , feature_names=X_train_all.columns)\n",
    "xgbtrain = xgb.DMatrix(data = X_train, label = y_train\n",
    "#                        , weight = X_weights_train\n",
    "                       , feature_names=X_train.columns)\n",
    "xgbval = xgb.DMatrix(data = X_val, label = y_val\n",
    "#                      , weight = X_weights_test\n",
    "                     , feature_names=X_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval-auc:0.605486\n",
      "Will train until val-auc hasn't improved in 50 rounds.\n",
      "[50]\tval-auc:0.687928\n",
      "[100]\tval-auc:0.698862\n",
      "[150]\tval-auc:0.704005\n",
      "[200]\tval-auc:0.707869\n",
      "[250]\tval-auc:0.709713\n",
      "[300]\tval-auc:0.710797\n",
      "[350]\tval-auc:0.712017\n",
      "[400]\tval-auc:0.712822\n",
      "[450]\tval-auc:0.714277\n",
      "[500]\tval-auc:0.715488\n",
      "[550]\tval-auc:0.715876\n",
      "[600]\tval-auc:0.71677\n",
      "[650]\tval-auc:0.717363\n",
      "[700]\tval-auc:0.71803\n",
      "[750]\tval-auc:0.718898\n",
      "[800]\tval-auc:0.719493\n",
      "[850]\tval-auc:0.719643\n",
      "[900]\tval-auc:0.719646\n",
      "[950]\tval-auc:0.719691\n",
      "Stopping. Best iteration:\n",
      "[926]\tval-auc:0.71985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.03,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 1,\n",
    "    'n_estimators': 1000\n",
    "}\n",
    "\n",
    "# Get a first estimate of XGB `num_boost_rounds`\n",
    "first_model = xgb.train(xgb_params, xgbtrain, num_boost_round=1000\n",
    "                        , evals=[(xgbval, 'val')]\n",
    "                        , early_stopping_rounds=50, verbose_eval=50)\n",
    "\n",
    "num_boost_round = first_model.best_iteration\n",
    "#print(num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def feat_imp(model, n_features = 20):\n",
    "\n",
    "    #d = model.get_booster().get_fscore()\n",
    "    d = model.get_score(importance_type='weight')\n",
    "    ss = sorted(d, key=d.get, reverse=True)\n",
    "    top_names = ss[0:n_features]\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(n_features), [d[i] for i in top_names], color=\"b\", align=\"center\")\n",
    "    plt.xlim(-1, n_features)\n",
    "    plt.xticks(range(n_features), top_names, rotation='vertical')\n",
    "\n",
    "feat_imp(first_model, n_features = 10)\n",
    "plt.show()\n",
    "\n",
    "# feat_imp(first_model, n_features = 50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage3 Fit XGBoost model, tuning - marked as it takes too long to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def modelfit(alg, xgbtrain, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        cvresult = xgb.cv(xgb_param, xgbtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "                          metrics='auc', early_stopping_rounds=early_stopping_rounds,\n",
    "                          callbacks=[xgb.callback.print_evaluation(show_stdv=True)])\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train_all, y_train_all,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    X_train_all_pred = alg.predict(X_train_all)\n",
    "    X_train_all_predprob = alg.predict_proba(X_train_all)[:,1]\n",
    "    \n",
    "    #Print model report:\n",
    "    print('Model Report')\n",
    "    print('AUC Score (Train): {}'.format(metrics.roc_auc_score(y_train_all, X_train_all_predprob)))\n",
    "    \n",
    "    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    \n",
    "    return cvresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning max_depth and min_child_weight next after using a fixed learning rate and first estimate of number of trees\n",
    "parameters = {'nthread':[64]\n",
    "              ,'objective':['binary:logistic']\n",
    "              ,'learning_rate': [0.03]\n",
    "              ,'n_estimators': [num_boost_round]\n",
    "              ,'max_depth':range(3,10,2)\n",
    "              ,'min_child_weight': range(2,6,2)\n",
    "              ,'gamma': [0, .1, .2, .3, .4]\n",
    "              ,'subsample': [.6, .7, .8, .9]\n",
    "              ,'colsample_bytree': [.6, .7, .8, .9]\n",
    "              , 'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100]\n",
    "              }\n",
    "k = StratifiedKFold(n_splits=5)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "# grid_search = GridSearchCV(xgb_model,\n",
    "#                         parameters,\n",
    "#                         cv = 5,\n",
    "#                         n_jobs = 4,\n",
    "#                         scoring='roc_auc',\n",
    "#                         verbose=True)\n",
    "\n",
    "grid_search = RandomizedSearchCV(xgb_model,\n",
    "                                 parameters,\n",
    "                                 n_iter=30,\n",
    "                                 n_jobs = 4,\n",
    "                                 cv=k,\n",
    "                                 scoring='roc_auc',\n",
    "                                 verbose=50)\n",
    "\n",
    "grid_result = grid_search.fit(X_train_all, y_train_all)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning max_depth and min_child_weight next after using a fixed learning rate and first estimate of number of trees\n",
    "parameters = {'nthread':[64]\n",
    "              ,'objective':['binary:logistic']\n",
    "              ,'learning_rate': [0.03]\n",
    "              ,'n_estimators': [num_boost_round]\n",
    "#               ,'scale_pos_weight': [183.8801]\n",
    "              ,'subsample': [1]\n",
    "              ,'colsample_bytree': [0.8]\n",
    "              ,'max_depth':range(3,10,2)\n",
    "              ,'min_child_weight': range(2,6,2)\n",
    "              }\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "grid_search = GridSearchCV(xgb_model,\n",
    "                        parameters,\n",
    "                        cv = 5,\n",
    "                        n_jobs = 4,\n",
    "                        scoring='roc_auc',\n",
    "                        verbose=True)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(xgb_model,\n",
    "#                                  parameters,\n",
    "#                                  n_iter=5,\n",
    "#                                  cv=3,\n",
    "#                                  scoring='roc_auc',\n",
    "#                                  verbose=True)\n",
    "\n",
    "grid_result = grid_search.fit(X_train_all, y_train_all)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning gamma after fixing previous tuned best parameters\n",
    "parameters['max_depth'] = [grid_result.best_params_['max_depth']]\n",
    "parameters['min_child_weight'] = [grid_result.best_params_['min_child_weight']]\n",
    "parameters['gamma'] = [0, .1, .2, .3, .4]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model,\n",
    "                        parameters,\n",
    "                        cv = 5,\n",
    "                        n_jobs = 4,\n",
    "                        scoring='roc_auc',\n",
    "                        verbose=True)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(xgb_model,\n",
    "#                                  parameters,\n",
    "#                                  n_iter=5,\n",
    "#                                  cv=3,\n",
    "#                                  scoring='roc_auc',\n",
    "#                                  verbose=True)\n",
    "\n",
    "grid_result = grid_search.fit(X_train_all, y_train_all)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning row and column subsample parameters after fixing previous tuned best parameters\n",
    "parameters['gamma'] = [grid_result.best_params_['gamma']]\n",
    "parameters['subsample'] = [.6, .7, .8, .9]\n",
    "parameters['colsample_bytree'] = [.6, .7, .8, .9]\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model,\n",
    "                        parameters,\n",
    "                        cv = 5,\n",
    "                        n_jobs = 4,\n",
    "                        scoring='roc_auc',\n",
    "                        verbose=True)\n",
    "\n",
    "# grid_search = RandomizedSearchCV(xgb_model,\n",
    "#                                  parameters,\n",
    "#                                  n_iter=10,\n",
    "#                                  cv=3,\n",
    "#                                  scoring='roc_auc',\n",
    "#                                  verbose=True)\n",
    "\n",
    "grid_result = grid_search.fit(X_train_all, y_train_all)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning regularisation parameter after fixing previous tuned best parameters\n",
    "parameters['subsample'] = [grid_result.best_params_['subsample']]\n",
    "parameters['colsample_bytree'] = [grid_result.best_params_['colsample_bytree']]\n",
    "parameters['reg_alpha'] = [1e-5, 1e-2, 0.1, 1, 100]\n",
    "\n",
    "grid_search = GridSearchCV(xgb_model,\n",
    "                        parameters,\n",
    "                        cv = 5,\n",
    "                        n_jobs = 4,\n",
    "                        scoring='roc_auc',\n",
    "                        verbose=True)\n",
    "# grid_search = RandomizedSearchCV(xgb_model,\n",
    "#                                  parameters,\n",
    "#                                  n_iter=5,\n",
    "#                                  cv=3,\n",
    "#                                  scoring='roc_auc',\n",
    "#                                  verbose=True)\n",
    "\n",
    "grid_result = grid_search.fit(X_train_all, y_train_all)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters['reg_alpha'] = [grid_result.best_params_['reg_alpha']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for parameter in parameters:\n",
    "    parameters[parameter] = parameters[parameter][0]\n",
    "parameters['learning_rate'] = 0.01\n",
    "parameters['n_estimators'] = 3000\n",
    "parameters['silent'] = False\n",
    "parameters['max_delta_step'] = 0\n",
    "parameters['base_score'] = 0.5\n",
    "parameters['scoring'] ='roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvresult = modelfit(xgb.XGBClassifier(**parameters)\n",
    "         , xgbtrain_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters['n_estimators'] = cvresult.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit final model with learning rate = 0.01 and grid search tuned parameters.\n",
    "final_model = xgb.XGBClassifier(**parameters).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = final_model.predict_proba(X_val)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_val, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp(final_model,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 : DELIVER - Package all your process, findings and code into a reproducible document that can be understood by a business user. A repo of the code branch would be a great thing to have! This reproducible report* must answer the following questions:\n",
    "\n",
    "How did you clean the data and what was wrong with it? Close to 90% of a Data Scientist's job is in cleaning data\n",
    "What are the features you used as-is and which one did you engineer using the given ones? What do they mean in the real world?\n",
    "What does the output look like - how close is the accuracy of the prediction in light of data with labelled flags?\n",
    "What other features and variables can you think of, that can make this process more robust? Can you make a recommendation of top 5 features you'd seek to find apart from the ones given here\n",
    "Summarize your findings in an executive summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How did you clean the data and what was wrong with it? Close to 90% of a Data Scientist's job is in cleaning data\n",
    "\n",
    "There are two clear issues with the training dataset:\n",
    "  a. There are duplicate records in training, they should be deduped.\n",
    "  b. Column \"days_since_last_order\" has been accidentally multiplied by 24. It should be restored by deviding by 24."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are the features you used as-is and which one did you engineer using the given ones? What do they mean in the real \n",
    "world?\n",
    "\n",
    "  a. Many count features(orders, cancels etc) are long tailed as shown in the diagram. There are two general approaches to solve the problem, either log transform to normalize or use tree based algorithm. I have used xgboost so it can be used without transform, but if I need to use neural network based appraoches. These long tailed features need to be normalized to the same/similar scale.\n",
    "  \n",
    "  b. For missing features(coupon_discount_applied), I have applied imputation(mostly replace by zero)\n",
    "  \n",
    "  c. For categorycal features (is_newsletter_subscriber, cc_payments, paypal_payments), I have applied one hot encoding.\n",
    "  \n",
    "  d. Days_since_first_purchase, Days_since_last_purchase and revenue at top three NON gendered related features that are most indicative to predict customers' gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3. What does the output look like - how close is the accuracy of the prediction in light of data with labelled flags?\n",
    " \n",
    "   a. There are ten features with gender labeled label. To make training infered label more reliable, I labeled male customers if they have no transaction of female related items. The vise versa for identifying female customers. \n",
    "   As these ten features male_items, mapp_items, mftw_items, macc_items, mspt_items, female_items, wapp_items, wftw_items, wacc_items, wspt_items have been used in defining training label and very indicative of gender they are excluded from the training and hyperparameter tuning process. According to the AUC of cross validation test, we achieved and AUC of 0.72 when NOT using any gender indicative features to do the prediction. Consider customers bought both female and male items are around 34%. The combined AUC will be around 90%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What other features and variables can you think of, that can make this process more robust? Can you make a recommendation of top 5 features you'd seek to find apart from the ones given here\n",
    "\n",
    "  a. There are three senario where we have different level of confidence of users' gender. \n",
    "    1. buy female labeled products only.\n",
    "    2. buy male labeled products only.\n",
    "    3. buy both female and male labeled products.\n",
    "  we can easily and more confidently determine customer gender for scenario 1 and 2. For senario3, it is difficult. But if we learn from scenario 1 and 2 the non gendered item transaction propensity, we can test and validate our best guess. \n",
    "\n",
    "  b. There is no validation process that help to confirm customer genders. To make the prediction more robust, especially for scenario 3, a email campaign or online survey or \n",
    "  \n",
    "  c. Female is known have different shopping behavior from male. I would suggest to collect\n",
    "  * online account username, email name \n",
    "  * online shopping session duration (aggregated per session)\n",
    "  * ratio between visits and purchases\n",
    "  * premiumship of product purchaseed (whether products purchased are generally low or upper end products)\n",
    "  * IPI (inter purchase interval) for each customer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. refer to the PPT attached "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
